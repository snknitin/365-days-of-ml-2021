# Day 291 of ML 

## PyTorch -  Things you should know

I already made some notes [here](https://github.com/snknitin/PyTorch_learn)

* Consider checkpointing. You can trade-off memory for compute by using checkpoint. PyTorch uses a caching memory allocator to speed up memory allocations. As a result, the values shown in nvidia-smi usually don’t reflect the true memory usage

* If your GPU memory isn’t freed even after Python quits, it is very likely that some Python subprocesses are still alive. You may find them via `ps -elf | grep python` and manually kill them with `kill -9 [pid]`.

* Don’t accumulate history across your training loop. Convert some differentiable variables with autograd hisory into floats if you are just accumulating the value 

*  Don’t hold onto tensors and variables you don’t need.  You will get the best memory usage if you don’t hold onto temporaries you don’t need. Use `del variable_name`


* Avoid running RNNs on sequences that are too large. The amount of memory required to backpropagate through an RNN scales linearly with the length of the RNN input; thus, you will run out of memory if you try to feed an RNN a sequence that is too long.  implement `truncated BPTT`

* Don’t use linear layers that are too large. A linear layer nn.Linear(m, n) uses O(nm)O(nm) memory: that is to say, the memory requirements of the weights scales quadratically with the number of features. It is very easy to blow through your memory this way (and remember that you will need at least twice the size of the weights, since you also need to store the gradients.)

* 

**References**
------------
[1]  https://github.com/snknitin/PyTorch_learn   
[2] https://d2l.ai/chapter_notation/index.html  