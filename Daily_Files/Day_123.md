# Day 123 of ML 

## Optuna - Hyper parameter tuning


Optuna is a next-generation automatic hyperparameter tuning framework written completely in Python.
Its most prominent features are:
* The ability to define Pythonic search spaces using loops and conditionals.
* Platform-agnostic API — you can tune estimators of almost any ML, DL package/framework, including Sklearn, PyTorch, TensorFlow, Keras, XGBoost, LightGBM, CatBoost, etc.
* a large suite of optimization algorithms with early stopping and pruning features baked in.
* Easy parallelization with little or no changes to the code.
* Built-in support for visual exploration of search results.

This is a distinct advantage over other similar tools because after the search is done, they completely forget the history of previous trials. Optuna does not. In Optuna, the whole optimization process is called a `study` . A study needs a function it can optimize. Typically, this function is defined by the user, should be named `objective` and expected to have this signature. The first thing you do in an objective function is to create the search space using built-in Optuna methods. It should accept an `optuna.Trial` object as a parameter and return the metric we want to optimize for. 
* If the metric we want to optimize is a point-performance score like ROC AUC or accuracy, we set the `direction to maximize`. 
* Otherwise, we minimize a loss function like RMSE, RMSLE, log loss, etc. by setting `direction to minimize`.

The search space is a plain-old dictionary. To create possible values to search over, you must use the trial object’s `suggest_*` functions. To make the space smaller, suggest_float and suggest_int have additional step or log arguments

Optuna has several classes responsible for parameter sampling. These are:
* **GridSampler**: the same as GridSearch of Sklearn. Never use for large search spaces!
* **RandomSampler**: the same as RandomizedGridSearch of Sklearn.
* **TPESampler**: Tree-structured Parzen Estimator sampler - bayesian optimization using kernel fitting. This is used by default.it tries to sample hyperparameter candidates by improving on the last trial’s scores. In other words, you can expect incremental (maybe marginal) improvements from trial to trial with this sampler.
* **CmaEsSampler**: a sampler based on CMA ES algorithm (does not allow categorical hyperparameters).

Optuna offers a wide range of plots under its visualization subpackage. To turn on the pruning feature, you need to call report() and should_prune() after each step of the iterative training. report() periodically monitors the intermediate objective values. should_prune() decides termination of the trial that does not meet a predefined condition.

```python
import logging
import sys
import optuna 
from optuna.samplers import CmaEsSampler, RandomSampler  
# Add stream handler of stdout to show the messages
optuna.logging.get_logger("optuna").addHandler(logging.StreamHandler(sys.stdout))
study_name = "example-study"  # Unique identifier of the study.
storage_name = "sqlite:///{}.db".format(study_name)
study = optuna.create_study(study_name=study_name, storage=storage_name)

study = optuna.create_study(direction="maximize")

# Study with a random sampler
study = optuna.create_study(sampler=RandomSampler(seed=1121218))
# Study with a CMA ES sampler
study = optuna.create_study(sampler=CmaEsSampler(seed=1121218))


def objective(trial: optuna.Trial):
    """Conventional optimization function
    signature for optuna.
    """
    custom_metric = ...
    return custom_metric

# method that takes the name of the hyperparameter and the range to look for its optimal value
# trial.suggest_integer('x',-7,7)
# is almost the same as {"x": np.arange(-7, 7)} when doing GridSearch

# trial.suggest_float()
# trial.suggest_categgorical()

from sklearn.ensemble import GradientBoostingRegressor
def objective(trial):
    params = {
        "n_estimators": trial.suggest_int("n_estimators", 1000, 10000, step=200),
        "learning_rate": trial.suggest_float("learning_rate", 1e-7, 0.3, log=True),
        "max_depth": trial.suggest_int("max_depth", 3, 12, step=2),
        "random_state": 1121218,
    }
    boost_reg = GradientBoostingRegressor(**params)
    rmsle = ...
    return rmsle


# Optimization with 100 trials
study.optimize(objective, n_trials=100)
print("Best params: ", study.best_params)
print("Best value: ", study.best_value)
print("Best Trial: ", study.best_trial)
print("Trials: ", study.trials)


from optuna.visualization.matplotlib import plot_optimization_history
from optuna.visualization.matplotlib import plot_param_importances

plot_optimization_history(study);
plot_param_importances(study);

```





**References**
------------
[1]  https://towardsdatascience.com/7-cool-python-packages-kagglers-are-using-without-telling-you-e83298781cf4  
[2] https://towardsdatascience.com/why-is-everyone-at-kaggle-obsessed-with-optuna-for-hyperparameter-tuning-7608fdca337c  
