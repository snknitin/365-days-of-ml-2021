# Day 11 of ML 

# Day 10 of ML 

## Data Distribution Shifts and Monitoring


### Types of Data Distribution Shifts

Let’s call the inputs to a model X and its outputs Y. We know that in supervised learning, the training data can be viewed as a set of samples from the joint distribution P(X, Y) and then ML usually models P(Y|X). P(Y|X) denotes the conditional probability of an output given an input — for example, the probability of an email being spam given the content of the email. P(X) denotes the probability density of the input. P(Y) denotes the probability density of the output. This joint distribution P(X, Y) can be decomposed in two ways:

    P(X, Y) = P(Y|X)P(X)
    P(X, Y) = P(X|Y)P(Y)


* **Covariate shift** is when P(X) changes, but P(Y|X) remains the same. Which means that the distribution of the input changes, but the conditional probability of a label given an input remains the same. This refers to the first decomposition of the joint distribution.
    * In statistics, a covariate is an independent variable that can influence the outcome of a given statistical trial, but which is not of direct interest. 
    * Consider that you are running an experiment to determine how locations affect the housing prices. The housing price variable is your direct interest, but you know the square footage affects the price, so the square footage is a covariate. In supervised ML, the label is the variable of direct interest, and the input features are covariate variables.
    * During model development, covariate shifts can happen because of biases during the data selection process, which could result from the difficulty in collecting examples for certain classes. During model development, covariate shifts can happen because of biases during the data selection process, which could result from the difficulty in collecting examples for certain classes.
    * Covariate shifts can also happen because the training data is artificially altered to make it easier for your model to learn. It’s hard for ML models to learn from imbalanced datasets, so you might want to collect more samples of the rare classes or oversample your data on the rare classes to make it easier for your model to learn the rare classes.
    * Covariate shift can also be caused by the model’s learning process, especially through active learning. In a previous lecture, we defined active learning as follows: instead of randomly selecting samples to train a model on, we use samples most helpful to that model according to some heuristics. This means that the training input distribution is altered by the learning process to differ from the real-world input distribution, and covariate shifts are a by-product
    * In production, covariate shift usually happens because of major changes in the environment or in the way your application is used. Imagine you have a model to predict how likely a free user will convert to a paid user. The income level of the user is a feature. Your company’s marketing department recently launched a campaign that attracts users from a demographic more affluent than your current demographic. The input distribution into your model has changed, but the probability that a user with a given income level will convert remains the same.
    *  you can leverage techniques such as **importance weighting** to train your model to work for the real world data. Importance weighting consists of two steps: estimate the density ratio between the real-world input distribution and the training input distribution, then weight the training data according to this ratio, and train an ML model on this weighted data
    * There has been research that attempts to help models learn representations of latent variables that are invariant across data distributions,
    
    
* **Label shift** is when P(Y) changes, but P(X|Y) remains the same. This refers to the second decomposition of the joint distribution.
    * Also known as **prior shift**, prior probability shift or target shift, is when P(Y) changes but P(X|Y) remains the same. You can think of this as the case when the output distribution changes but for a given output, the input distribution stays the same.
    * Covariate shift is when the input distribution changes. When the input distribution changes, the output distribution also changes, resulting in both covariate shift and label shift happening at the same time
    * 

* **Concept drift** is when P(Y|X) changes, but P(X) remains the same. This refers to the first decomposition of the joint distribution20.


**References**
------------
[1]  https://huyenchip.com/2022/02/07/data-distribution-shifts-and-monitoring.html  
[2]