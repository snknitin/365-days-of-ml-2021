# Day 124 of ML 


## Sklearn tips and tricks 


If you are dealing with millions of rows, at this stage, don’t use models in Sklearn because they are CPU-only. **Choose from XGBoost, LightGBM or CatBoost**. And here is the surprising fact — **XGBoost is much slower than the other two, even on GPUs**. It is up to 10 times slower than LightGBM. `CatBoost` beats both libraries, and the speed difference grows rapidly as the dataset size gets bigger. It also regularly outperforms them in terms of accuracy.

These speed differences become much more pronounced when you are running multiple experiments, cross-validating, or hyperparameter tuning.


* To apply min max scaling to specific columns in a dataframe or for a single column, use this

```python

from sklearn.preprocessing import minmax_scale

product_df['price'] = minmax_scale(product_df['price'].astype(np.float64))

```


**References**
------------
[1]  https://towardsdatascience.com/scale-standardize-or-normalize-with-scikit-learn-6ccc7d176a02
[2]
