# Day 1 of ML 


**ML Basics**

* Events are expressions about random variables. 
* Two events are mutually exclusive if they cannot both be true. 
* p(x,y) = p(y,x) = p(x or y)
* An important distinction in conditional probability or bayes rule is that , p(x|y) is the probability of event x conditioned of knowing event y. Even though we are used to saying x given y, y doesn't not need to have occurred.
* Conditioning means that some states or configurations are now unavailable and the probability needs to be distributed across the remaining states. So it is not, given y has occurred , what is the probability of event  x. It is probability of x being in a particular state under the constraint that y is in a selected state.
* The best way to think about statistical independence is asking if knowing or not knowing the state of one variable y gives you something more than what you knew before about variable x, from the joint distribution p(x,y) to figure out the marginal p(x) which is a sum over all states of y
* XTY|Z for X and Y to be conditionally independent , it should be over all states of z ie., p(x,y|z) = p(x|z)p(y|z), but bear in mind, that conditional independence is not transitive, ie., a->b, b->c does not mean a->c and neither does dependency



**RL**

* 












**References**
------------
[1] Bayesian Reasoning and ML, David Barber  
[2] https://distill.pub/2020/understanding-rl-vision/