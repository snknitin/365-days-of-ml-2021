# Day 122 of ML 

## Numpy - Tips and Tricks

* You may have used `np.zeroes_like` or `np.ones_like`. np.full_like takes in a matrix and a fill value and creates the whole matrix
* `linspace`  can create a custom number of linearly spaced data points within an interval. `logspace` takes this a bit further. It can generate a custom number of points evenly spaced on a logarithmic scale. 
* you can create every possible coordinate pair from a given X and Y arrays using `meshgrid` . is usually used for more complex tasks that would take forever if done with loops
* `np.triu` and `np.tril` are upper and lower and return zeros above or below a certain diagonal of a matrix .  create a boolean mask with True values above the main diagonal when plotting a correlation heatmap. mask created with triu can be used on a correlation matrix to drop the unnecessary upper triangle and the diagonal. This leaves a much more compact and readable heatmap devoid of clutter.
* Takes arrays and crush them into 1D using `np.ravel` or `np.flatten` .  flatten always returns a 1D copy while ravel tries to produce a 1D view of the original array. So, **be careful because modifying the returned array from ravel might change the original array**. 
* `np.vstack` and `np.hstack` are useful when you want tocombine arrays into a single matrix for example, ensemble of model predictions. Remember to do `.reshape(-1, 1)` to each array because stacking needs them to be 2D . represents converting the array to a single column with as many rows as possible. To call reshape on all your arrays, there is a much more elegant solution. `np.r_` and `np.c_` operators (not functions!) allow stacking arrays as rows and columns, respectively. Since they are operators you use `[]` and not `()` . np.c_ stacks the arrays next to each other, creating a matrix. However, their functionality isn't limited to simple horizontal and vertical stacks. They are much more powerful than that
* `np.all` only returns True if all elements inside an array match a specific condition while `np.any` returns True if at least one element of an array satisfies a particular condition.
* use `np.allclose` which returns True if all elements of an array are close to each other, given some tolerance.
* If you need the indices that would sort an array to use the same indices multiple times over for different purposes, use `np.argsort`
* `np.isneginf` and `np.isposinf` - These two boolean functions check if an element in an array is negative infinity or positive infinity. represent infinity as some extremely large or small number they can fit into a single bit , which is why np.inf returns float 
* `np.polyfit` can take two vectors, apply linear regression on them and return a slope and an intercept. You just have to specify the degree with deg, because this function can be used to approximate the roots of any degree polynomial.
* Get a list of nan related functions so that having one nan value won't return nans all the time
* `np.clip` is useful when you want to impose a strict limit on the values of your array
* check the number of non-zero elements in any array with `np.count_nonzero` . common to work with sparse arrays
* `np.array_split` used to chunk ndarrays or DataFrames into N buckets. Besides, it doesn't raise an error when you want to split the array into non-equal sized chunks like `np..vsplit`

```python
import numpy as np
array_w_inf = np.full_like(array, fill_value=np.pi, dtype=np.float32)
log_array = np.logspace(start=1, stop=100, num=15, base=np.e)

x = [1, 2, 3, 4]
y = [3, 5, 6, 8]

xx, yy = np.meshgrid(x, y)

matrix = df.corr()
mask = np.triu(np.ones_like(matrix, dtype=bool))

preds1 = np.random.rand(100)
preds2 = np.random.rand(100)

as_rows = np.r_[preds1, preds2] # (200,)
as_cols = np.c_[preds1, preds2] # (100,2)

np.allclose(a1, a2, rtol=0.2) #  returns True only if the differences are smaller (<) than rtol, not <=!

idx = np.argsort(arr)

X = df["col1"].values.flatten()
y = df["col2"].values.flatten()

slope, intercept = np.polyfit(X, y, deg=1)


[func for func in dir(np) if func.startswith("nan")]
np.nanmean(arr)

splitted_dfs = np.array_split(df, 100)
```



**References**
------------
[1]  https://towardsdatascience.com/25-numpy-functions-you-never-knew-existed-p-guarantee-0-85-64616ba92fa8
[2]