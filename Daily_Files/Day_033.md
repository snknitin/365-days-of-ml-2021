# Day 33 of ML 

## Tuning ML algorithms and why it is hard

In machine learning, linear combinations of losses are all over the place. it is common for these objectives to be given additional regularisation.
Especially regarding how these linear combinations make your algorithm hard to tune


* Lot of problems in machine learning should be treated as multi-objective problems, while they currently are not.
* This lack of multi-objective treatment leads to difficulties in tuning the hyper-parameters for these machine learning algorithms.
* It is nigh on impossible to detect when these problems are occurring, making it tricky to work around them.

If an algorithm does not work for your problem, you need to spend more time tuning the hyper-parameters to your problem. 
* All of these losses have something in common, they are effectively trying to optimise for multiple objectives simultaneously, and argue that the optimum is found in balancing these often contradicting forces.
* In some cases, the sum is more ad hoc and a hyper-parameter is introduced to weigh the parts against each other. In some cases, there are clear theoretical foundations on why the losses are combined this way, and no hyper-parameter is used for tuning the balance between the parts.


It seems that no matter how we finetune our α-parameter, we cannot make a good trade-off between our two losses.
The thing which has changed between these problems is the model. In other words, the effect the model parameters θ have on the output of the model is different.


**Pareto front** - This is the set of all solutions achievable by our model, which are not dominated by any other solution.
 In other words, it is the set of achievable losses, where there is no point where all of the losses are better. No matter how you choose to trade off between the two losses, your preferred solution always lies on the Pareto front.
 By tuning the hyper-parameter of your loss, you usually hope to merely find a different point on that same front.
Note that in most applications, Pareto fronts are not either convex or concave, but they are a mix of both. This amplifies the problem.


* It turns out that when the Pareto front is convex, we can achieve all possible trade-offs by tuning our α-parameter. 
* However, when the Pareto front is concave, that approach does not seem to work well anymore.

        gradient descent optimisation fails for concave Pareto fronts because it is a saddle point

Look at visualizations on the blog for better understanding 

### Things to remember

1) First off, even if you do not introduce a hyper-parameter to weigh off between the losses, it is not correct to say that gradient descent will try to balance between counteracting forces.  
2) Second, even when a hyper-parameter is introduced, this hyper-parameter is tuned on a try-and-see basis.   
3) Thirdly, the hyper-parameter cannot tune for all optima. No matter how much you tune and keep fine-tuning, you will not find the intermediate solutions you might be interested in. Not because they do not exist, as they most certainly do, but because a poor approach was chosen for combining these losses.
4) Fourthly, it is important to stress that for practical applications, it is always unknown whether the Pareto front is convex and therefore whether these loss weights are tunable. Whether they are good hyper-parameters depends on how your model is parameterised, and how this affects the Pareto curve.   
5) 

## Causal design patterns


**References**
------------
[1]  https://engraved.ghost.io/why-machine-learning-algorithms-are-hard-to-tune/?utm_campaign=Data_Elixir&utm_source=Data_Elixir_321  
[2] https://engraved.ghost.io/how-we-can-make-machine-learning-algorithms-tunable/  
[3] https://emilyriederer.netlify.app/post/causal-design-patterns/?utm_campaign=Data_Elixir&utm_source=Data_Elixir_321 