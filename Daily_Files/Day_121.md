# Day 121 of ML 

## Pandas Tips and Tricks 

* **Loading the data** -  when you have large ccsv files, it takes a huge time to load especially when you have million rows. Don't use pandas to load it.  You cna also try Dask, Vaex or cuDF

```python
import datatable as dt
df = dt.fread("data/train.csv").to_pandas()
```

* **Operations without loops** -  Instead of using apply function on multiple columns in a row using lambda, pull them out as df.values and create a new column by sending these arrays of the features as argument to a function. 

```python
df["new"] = df.apply(lambda row : big_func(row["col1"],row["col2"],row["col3"],axis=1) 
df["new"] = big_func(df["col1"].values,df["col2"].values,df["col3"].values) 
```

* **Change data type too load quicker** - object type is a menace for categorical values and takes up too much space but that also happens for other data types. Here is a useful helper method 

```python
def reduce_memory_usage(df, verbose=True):
    numerics = ["int8", "int16", "int32", "int64", "float16", "float32", "float64"]
    start_mem = df.memory_usage().sum() / 1024 ** 2
    for col in df.columns:
        col_type = df[col].dtypes
        if col_type in numerics:
            c_min = df[col].min()
            c_max = df[col].max()
            if str(col_type)[:3] == "int":
                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:
                    df[col] = df[col].astype(np.int8)
                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:
                    df[col] = df[col].astype(np.int16)
                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:
                    df[col] = df[col].astype(np.int32)
                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:
                    df[col] = df[col].astype(np.int64)
            else:
                if (
                    c_min > np.finfo(np.float16).min
                    and c_max < np.finfo(np.float16).max
                ):
                    df[col] = df[col].astype(np.float16)
                elif (
                    c_min > np.finfo(np.float32).min
                    and c_max < np.finfo(np.float32).max
                ):
                    df[col] = df[col].astype(np.float32)
                else:
                    df[col] = df[col].astype(np.float64)
    end_mem = df.memory_usage().sum() / 1024 ** 2
    if verbose:
        print(
            "Mem. usage decreased to {:.2f} Mb ({:.1f}% reduction)".format(
                end_mem, 100 * (start_mem - end_mem) / start_mem
            )
        )
    return df
```


* **Style on describe for easy viewing** -  You can display stylized dataframes. Raw df are rendered as html tables with a bit of CSS inside jupyter 

```python
df.sample(20,axis=1).describe().T.style.bar(subset=['mean'],color='#205ff2').background_gradient(subset=['std'],cmaps='Reds').background_gradient(subset=['50%'],cmap='coolwarm')
```

* Save dataframes as feathers or parquets instead.


**References**
------------
[1]  https://towardsdatascience.com/25-pandas-functions-you-didnt-know-existed-p-guarantee-0-8-1a05dcaad5d0  
[2]